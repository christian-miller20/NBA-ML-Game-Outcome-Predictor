{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmille47/CorbyRowKickoffDarty2022/blob/main/MLALG1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT5JVjwPNYjw"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import tensorflow as tf\n",
        "from sklearn import model_selection\n",
        "import torch\n",
        "\n",
        "#data filepath\n",
        "DATA_PATH = \"/content/drive/MyDrive/MLPROJECT/notpie.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biY73KyxOKmL",
        "outputId": "5e626d13-ae1f-4665-f429-89962cca1457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPO3tkg1NYj0"
      },
      "outputs": [],
      "source": [
        "def load_data(data_path):\n",
        "    \"\"\"Loads data dataset from csv file.\n",
        "\n",
        "        :param data_path (str): Path to json file containing data\n",
        "        :return X (ndarray): Inputs\n",
        "        :return y (ndarray): Targets\n",
        "    \"\"\"\n",
        "    #data filepath\n",
        "    filepath = data_path\n",
        "\n",
        "    #import csv using pandas to format into dataframe\n",
        "    with open(filepath, 'r') as f:\n",
        "        data = pandas.read_csv(f, header=None)\n",
        "\n",
        "    #print(data.head())\n",
        "    #randomize te rows of the dataframe\n",
        "    data = normalize_data(data)\n",
        "    data = data.sample(frac=1)\n",
        "    #load all columns except the last one into x\n",
        "    x = np.array(data.iloc[:, :-1])\n",
        "    y = np.array(data.iloc[:, -1])\n",
        "    \n",
        "    #print(\"Data succesfully loaded!\")\n",
        "\n",
        "    return  x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxZTXwi2NYj3"
      },
      "outputs": [],
      "source": [
        "def normalize_data(data):\n",
        "    for i in range((len(data.columns)-1)):\n",
        "        num = data[i].max()\n",
        "        if num < 1:\n",
        "            continue\n",
        "        if num < 10:\n",
        "            data[i] = (data[i]) / (10)\n",
        "        elif num < 100:\n",
        "            data[i] = (data[i]) / (100)\n",
        "        elif num < 1000:\n",
        "            data[i] = (data[i]) / (1000)\n",
        "        else:\n",
        "            print(\"Error in normalization! Please check!\")\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = load_data(\"/content/drive/MyDrive/MLPROJECT/fd3.csv\")\n",
        "train_ratio = 0.60\n",
        "validation_ratio = 0.20\n",
        "test_ratio = 0.20\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid() \n",
        "    def forward(self, x):\n",
        "        hidden = self.fc1(x)\n",
        "        relu = self.relu(hidden)\n",
        "        output = self.fc2(relu)\n",
        "        output = self.sigmoid(output)\n",
        "        return output\n",
        "\n",
        "#convert to tensors\n",
        "training_input = torch.FloatTensor(x_train)\n",
        "training_output = torch.FloatTensor(y_train)\n",
        "test_input = torch.FloatTensor(x_test)\n",
        "test_output = torch.FloatTensor(y_test)\n",
        "\n",
        "input_size = training_input.size()[1] # number of features selected\n",
        "hidden_size = 20 # number of nodes/neurons in the hidden layer\n",
        "model = Net(input_size, hidden_size) # create the model\n",
        "criterion = torch.nn.BCELoss() # works for binary classification\n",
        "# without momentum parameter\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr = 0.9) \n",
        "#with momentum parameter\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.9, momentum=0.25)"
      ],
      "metadata": {
        "id": "DudyuSUr26QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/MLPROJECT/best2.pth'))\n",
        "model.train()\n",
        "epochs = 5000\n",
        "errors = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(training_input)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred.squeeze(), training_output)\n",
        "    errors.append(loss.item())\n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "def accuracy(model, inp, out):\n",
        "  # ds is a iterable Dataset of Tensors\n",
        "  # one item at a time version\n",
        "  model.load_state_dict(torch.load('/content/drive/MyDrive/MLPROJECT/best2.pth'))\n",
        "  guesses = []\n",
        "  guess = ()\n",
        "  n_correct = 0; n_wrong = 0\n",
        "\n",
        "  for i in range(len(inp)):\n",
        "    inpts = inp[i]\n",
        "    target = out[i]   # float32  [0.0] or [1.0]\n",
        "    with torch.no_grad():\n",
        "      oupt = model(inpts)\n",
        "    guess = (target, oupt.round())\n",
        "    print(guess)\n",
        "\n",
        "    # avoid 'target == 1.0'\n",
        "    if guess[0]==guess[1]:\n",
        "      n_correct += 1\n",
        "    else:\n",
        "      n_wrong += 1\n",
        "\n",
        "  return (n_correct * 1.0) / (n_correct + n_wrong)\n",
        "\n",
        "acc = accuracy(model,test_input,test_output)\n",
        "print(f'Accuracy: {acc}')"
      ],
      "metadata": {
        "id": "l5sXyn7d35c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "game1 = x[0]\n",
        "wL = y[0]\n",
        "print(x.shape)\n",
        "print(game1)\n",
        "print(wL)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/MLPROJECT/.pth')\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/MLPROJECT/best.pth'))\n",
        "oupt = model(torch.FloatTensor(game1))\n",
        "print(oupt.item())\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "dNlqlzpM6WJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotcharts(errors):\n",
        "    errors = np.array(errors)\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    graf02 = plt.subplot(1, 2, 1) # nrows, ncols, index\n",
        "    graf02.set_title('Errors')\n",
        "    plt.plot(errors, '-')\n",
        "    plt.xlabel('Epochs')\n",
        "    graf03 = plt.subplot(1, 2, 2)\n",
        "    graf03.set_title('Tests')\n",
        "    a = plt.plot(test_output.numpy(), 'yo', label='Real')\n",
        "    plt.setp(a, markersize=10)\n",
        "    a = plt.plot(y_pred.detach().numpy().round(), 'b+', label='Predicted')\n",
        "    plt.setp(a, markersize=10)\n",
        "    plt.legend(loc=7)\n",
        "    plt.show()\n",
        "\n",
        "plotcharts(errors)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eNHaHJFP4IvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_pred = model(test_input)\n",
        "after_train = criterion(y_pred.squeeze(), test_output)\n",
        "print('Test loss after training' , after_train.item())"
      ],
      "metadata": {
        "id": "ZvakIJMh9gU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QK60s_LeAtw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, inp, out):\n",
        "  # ds is a iterable Dataset of Tensors\n",
        "  # one item at a time version\n",
        "  n_correct = 0; n_wrong = 0\n",
        "\n",
        "  for i in range(len(inp)):\n",
        "    inpts = inp\n",
        "    target = test_output   # float32  [0.0] or [1.0]\n",
        "    with torch.no_grad():\n",
        "      oupt = model(inpts)\n",
        "\n",
        "    # avoid 'target == 1.0'\n",
        "    if (target < 0.5)  (oupt = 0.5) and (oupt >= 0.5):\n",
        "      n_correct += 1\n",
        "    else:\n",
        "      n_wrong += 1\n",
        "\n",
        "  return (n_correct * 1.0) / (n_correct + n_wrong)\n",
        "\n",
        "  print(accuracy(model))"
      ],
      "metadata": {
        "id": "YM2Zlp2e-9Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy(model,test_input,test_output)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "QlkG3OqiCroy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "4d2770c334f3778740193ba4b3686745ae5c2e3ee10c8c0d673798cf1c2fcefe"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('tf': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Copy of MLALG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}